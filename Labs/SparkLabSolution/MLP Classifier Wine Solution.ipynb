{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Dataset\n",
    "## Wines are categorized into 3 customer segments based on featuers listed below:\n",
    "### Features are:\n",
    "\n",
    "<ol>\n",
    "    <li>Alcohol</li>\n",
    "    <li>Malic acid</li>\n",
    "    <li>Ash</li>\n",
    "    <li>Alcalinity of ash</li>\n",
    "    <li>Magnesium</li>\n",
    "    <li>Total phenols</li>\n",
    "    <li>Flavanoids</li>\n",
    "    <li>Nonflavanoid phenols</li>\n",
    "    <li>Proanthocyanins</li>\n",
    "    <li>Color intensity</li>\n",
    "    <li>Hue</li>\n",
    "    <li>OD280/OD315 of diluted wines</li>\n",
    "    <li>Proline </li>\n",
    "    </ol>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment for using pyspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Application Context\n",
    "spark = SparkSession.builder.appName(\"Wine Dataset MLP\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.format('csv').options(header='true', inferSchema='true').load('../datasets/Wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'tomato'>\n",
    "<h3>Data preparation</h3>\n",
    "1. Convert the Customer_Segment (string) to label (number) <br>\n",
    "2. Create features using Vector Assembler<br>\n",
    "3. Create training and test set <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target column to numbers\n",
    "labelIndexer = StringIndexer(inputCol=\"Customer_Segment\", outputCol=\"label\").fit(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = labelIndexer.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all columns except Customer_Segment and label\n",
    "fcols = df.columns[:-2]\n",
    "fcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features into vector assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vassemb = VectorAssembler(inputCols = fcols, outputCol = 'features')\n",
    "ndf = vassemb.transform(df)\n",
    "ndf = ndf.select(['label', 'features'])\n",
    "\n",
    "ndf.show(3, truncate = False)\n",
    "#ndf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"stdFeatures\",\n",
    "                        withStd=False, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerModel = scaler.fit(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData = scalerModel.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaledData.select(\"stdFeatures\").show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = scaledData.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'tomato'>\n",
    "    <h3>Use MultiLayerPerceptron Classifier </h3>\n",
    "    <ol>\n",
    "        <li>Create MultiLayerPerceptronClassifier instance</li>\n",
    "        <li>Make sure to define layers</li>\n",
    "        <li>Fit the transformed features</li>\n",
    "        <li>Transform the model</li>\n",
    "        <li>Evaluate the model using multi-class classification evaluator</li>\n",
    "        <li>Print Test Data accuracy</li>\n",
    "        <li>Create Confusion Matrix</li>\n",
    "    </ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayerPerceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 13 features and 3 Classes - Customer Segments)\n",
    "layers = [13, 9, 7, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilayerPerceptronClassifier(featuresCol = 'stdFeatures', labelCol = 'label',\n",
    "                                         maxIter = 100, layers = layers, blockSize = 3,\n",
    "                                         seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = result.select(\"prediction\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.select('label', 'prediction', 'probability', 'features').show(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = result.select('label')\n",
    "y_true = y_true.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = result.select('prediction')\n",
    "y_p = y_p.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_p)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cseg = [\"Seg-1\", \"Seg-2\", \"Seg-3\"]\n",
    "cm_df = pd.DataFrame(cm, index = cseg, columns = cseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_df, annot=True, cmap = 'Blues', annot_kws={\"size\": 16})\n",
    "plt.title('Wine Customers Confusion Matrix\\n')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
